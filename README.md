# Stock Prediction System

End-to-end stock prediction project with:
- Training notebook for LSTM regression and Random Forest classification.
- FastAPI service that serves predictions and metrics.
- Streamlit dashboard that visualizes predictions and metrics.

## System Architecture (High Level)

```
+---------------------+        HTTP        +---------------------+
|  Streamlit UI       | <----------------> |     FastAPI API     |
|  app.py             |                    |     api.py          |
+---------------------+                    +---------------------+
            ^                                         ^
            |                                         |
            | reads metrics/forecast                  | loads models/scalers
            | via API                                 | from models/
            |                                         |
            |                                         |
     +---------------+                         +---------------+
     | metrics/      |                         | models/       |
     | JSON outputs  |                         | .h5/.pkl/.csv |
     +---------------+                         +---------------+
            ^
            |
            | generated by
            |
     +---------------+
     | train.ipynb   |
     | data/ CSVs    |
     +---------------+
```

## What Each Part Does

### 1) Training Notebook (train.ipynb)
- Loads each stock CSV in data/.
- Trains an LSTM model to predict the next closing price.
- Trains a RandomForestClassifier to predict UP/DOWN movement.
- Saves models and artifacts:
  - LSTM: models/<STOCK>_lstm.h5
  - Scaler: models/<STOCK>_scaler.pkl
  - Classifier: models/<STOCK>_rf.pkl
  - Metrics: metrics/<STOCK>_roc.json, metrics/<STOCK>_confusion.json, metrics/<STOCK>_regression_curve.json
  - Metrics: metrics/<STOCK>_loss.json, metrics/<STOCK>_error_trend.json
  - Metrics: metrics/<STOCK>_regression_metrics.json
  - Metrics: metrics/<STOCK>_classification_metrics.json, metrics/<STOCK>_classification_report.json
  - Metrics: metrics/lstm_table.json

LSTM workflow summary:
- Close prices are cleaned and missing values are imputed.
- MinMaxScaler -> sliding window sequences (default window=30).
- Time-ordered train/validation/test split.
- LSTM predicts next value; inverse transform returns price.
- Regression curve JSON stores actual vs predicted.
- Loss curves, regression metrics, and error trend are stored as JSON.

Classifier workflow summary:
- Feature is last close price (one-step lag).
- Label is UP (1) if next close is higher; else DOWN (0).
- Random Forest predicts UP probability.
- ROC, confusion matrix, and classification report/metrics are stored as JSON.

### 2) API Service (api.py)
FastAPI loads all models/scalers once at startup and serves endpoints per stock:
- GET /predict/regression/{stock}
  - Loads last 60 closes from data/<stock>.csv.
  - Scales, predicts next close using LSTM.
- GET /predict/classification/{stock}
  - Uses RandomForest on last close to predict UP/DOWN.
- GET /metrics/roc/{stock}
- GET /metrics/confusion/{stock}
- GET /metrics/regression_curve/{stock}
- GET /metrics/loss/{stock}
- GET /metrics/error/{stock}
- GET /metrics/regression/{stock}
- GET /metrics/classification/{stock}
- GET /metrics/classification/report/{stock}
- GET /metrics/lstm_table
- GET /forecast/30days/{stock}
  - Serves precomputed forecast if file exists.

### 3) Streamlit Dashboard (app.py)
- Calls the API and visualizes results.
- Tabs:
  - Classification: prediction, ROC curve, confusion matrix, metrics, report.
  - Regression: predicted next close vs last actual, curve plot, loss curves, error trend, metrics, LSTM table.
  - 30-Day Forecast: plot and table (if forecast file exists).

## Data and Artifact Layout

- data/ - input CSVs (must contain a close column).
- models/ - trained models and scalers.
- metrics/ - JSON evaluation outputs for plots and tables.
- scalers/ - currently empty (scalers stored in models/).

## Packages Used

Core:
- fastapi
- numpy
- pandas
- joblib
- tensorflow (keras)
- scikit-learn

UI / Visualization:
- streamlit
- matplotlib
- requests

Standard library:
- json
- os

## How the System Works (End to End)

1) Run train.ipynb to train models and write metrics JSON files.
2) Start the FastAPI server; it loads all models/scalers into memory.
3) Launch Streamlit; it calls the API and renders charts.
4) Users pick a stock and see classification, regression, and forecast.

## How to Start the System

1) Install dependencies (one time):
  - pip install fastapi uvicorn streamlit numpy pandas joblib tensorflow scikit-learn matplotlib requests

2) Train models and generate metrics (optional if already trained):
  - Open train.ipynb and run all cells.
  - This writes model files into models/ and metrics JSON into metrics/.

3) Start API server:
  - uvicorn api:app --reload

4) Start Streamlit UI (new terminal):
  - streamlit run app.py

5) Open the Streamlit URL shown in terminal.

## One-Command Startup (Python)

Run this to start both API and UI in the same terminal session. If a .venv
exists, the script will automatically relaunch using it:

- python run.py --reload

## Notes and Assumptions

- data/<STOCK>.csv must include a close column.
- LSTM prediction uses the last 60 closes at request time.
- Classification uses only the most recent close (single feature).
- Forecast endpoint expects models/<STOCK>_30day_forecast.csv to exist.
