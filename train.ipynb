{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a05c7551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca3b7e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOCKS = [\"CGH\", \"LICN\", \"NABIL\", \"NIFRA\", \"UPPER\"]\n",
    "DATA_DIR = \"data\"\n",
    "MODEL_DIR = \"models\"\n",
    "METRIC_DIR = \"metrics\"\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(METRIC_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da43302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, window=30):\n",
    "    X, y = [], []\n",
    "    for i in range(window, len(data)):\n",
    "        X.append(data[i-window:i])\n",
    "        y.append(data[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def clean_close_series(df):\n",
    "    if \"close\" not in df.columns:\n",
    "        raise ValueError(\"Expected a 'close' column in the dataset\")\n",
    "    close = pd.to_numeric(df[\"close\"], errors=\"coerce\")\n",
    "    close = close.interpolate(method=\"linear\").ffill().bfill()\n",
    "    close = close.dropna()\n",
    "    return close.values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def split_time_series(X, y, train_ratio=0.7, val_ratio=0.15):\n",
    "    n = len(X)\n",
    "    train_end = int(n * train_ratio)\n",
    "    val_end = int(n * (train_ratio + val_ratio))\n",
    "    X_train = X[:train_end]\n",
    "    y_train = y[:train_end]\n",
    "    X_val = X[train_end:val_end]\n",
    "    y_val = y[train_end:val_end]\n",
    "    X_test = X[val_end:]\n",
    "    y_test = y[val_end:]\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ad13326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LSTM for CGH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samaw\\Desktop\\project\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step\n",
      "\n",
      "Training LSTM for LICN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samaw\\Desktop\\project\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n",
      "\n",
      "Training LSTM for NABIL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samaw\\Desktop\\project\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n",
      "\n",
      "Training LSTM for NIFRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samaw\\Desktop\\project\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step\n",
      "\n",
      "Training LSTM for UPPER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samaw\\Desktop\\project\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step\n"
     ]
    }
   ],
   "source": [
    "for stock in STOCKS:\n",
    "    print(f\"\\nTraining LSTM for {stock}\")\n",
    "\n",
    "    df = pd.read_csv(f\"{DATA_DIR}/{stock}.csv\")\n",
    "    close_prices = clean_close_series(df)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(close_prices)\n",
    "\n",
    "    X, y = create_sequences(scaled)\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = split_time_series(X, y)\n",
    "\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=(X.shape[1], 1)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    model.save(f\"{MODEL_DIR}/{stock}_lstm.h5\")\n",
    "    joblib.dump(scaler, f\"{MODEL_DIR}/{stock}_scaler.pkl\")\n",
    "\n",
    "    history_payload = {\n",
    "        \"loss\": [float(v) for v in history.history.get(\"loss\", [])],\n",
    "        \"val_loss\": [float(v) for v in history.history.get(\"val_loss\", [])],\n",
    "        \"final_loss\": float(history.history[\"loss\"][-1]),\n",
    "        \"final_val_loss\": float(history.history[\"val_loss\"][-1]),\n",
    "        \"generalization_gap\": float(history.history[\"val_loss\"][-1] - history.history[\"loss\"][-1])\n",
    "    }\n",
    "    with open(f\"{METRIC_DIR}/{stock}_loss.json\", \"w\") as f:\n",
    "        json.dump(history_payload, f)\n",
    "\n",
    "    # Save regression curve + error trend on test split\n",
    "    preds = model.predict(X_test)\n",
    "    actual = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "    predicted = scaler.inverse_transform(preds).flatten()\n",
    "    errors = actual - predicted\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"actual\": actual.tolist(),\n",
    "        \"predicted\": predicted.tolist()\n",
    "    }).to_json(f\"{METRIC_DIR}/{stock}_regression_curve.json\")\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"actual\": actual.tolist(),\n",
    "        \"predicted\": predicted.tolist(),\n",
    "        \"error\": errors.tolist()\n",
    "    }).to_json(f\"{METRIC_DIR}/{stock}_error_trend.json\")\n",
    "\n",
    "    regression_metrics = {\n",
    "        \"mse\": float(mean_squared_error(actual, predicted)),\n",
    "        \"rmse\": float(np.sqrt(mean_squared_error(actual, predicted))),\n",
    "        \"mae\": float(mean_absolute_error(actual, predicted)),\n",
    "        \"r2\": float(r2_score(actual, predicted))\n",
    "    }\n",
    "    with open(f\"{METRIC_DIR}/{stock}_regression_metrics.json\", \"w\") as f:\n",
    "        json.dump(regression_metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44b6a6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 30-day forecasts to models/\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "FORECAST_DAYS = 30\n",
    "\n",
    "for stock in STOCKS:\n",
    "    df = pd.read_csv(f\"{DATA_DIR}/{stock}.csv\")\n",
    "    close = df[\"close\"].values.reshape(-1, 1)\n",
    "\n",
    "    scaler = joblib.load(f\"{MODEL_DIR}/{stock}_scaler.pkl\")\n",
    "    model = load_model(f\"{MODEL_DIR}/{stock}_lstm.h5\", compile=False)\n",
    "\n",
    "    scaled = scaler.transform(close)\n",
    "    window = scaled[-60:].reshape(1, 60, 1)\n",
    "\n",
    "    preds = []\n",
    "    for _ in range(FORECAST_DAYS):\n",
    "        next_scaled = model.predict(window, verbose=0)[0][0]\n",
    "        preds.append(next_scaled)\n",
    "        next_step = np.array(next_scaled).reshape(1, 1, 1)\n",
    "        window = np.concatenate([window[:, 1:, :], next_step], axis=1)\n",
    "\n",
    "    preds_inv = scaler.inverse_transform(np.array(preds).reshape(-1, 1)).flatten()\n",
    "    out = pd.DataFrame({\n",
    "        \"day\": list(range(1, FORECAST_DAYS + 1)),\n",
    "        \"predicted_price\": preds_inv\n",
    "    })\n",
    "    out.to_csv(f\"{MODEL_DIR}/{stock}_30day_forecast.csv\", index=False)\n",
    "\n",
    "print(\"Saved 30-day forecasts to models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52bfa520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(prices):\n",
    "    return (prices[1:] > prices[:-1]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8031a44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier for CGH\n",
      "AUC for CGH: 0.502\n",
      "\n",
      "Training classifier for LICN\n",
      "AUC for LICN: 0.481\n",
      "\n",
      "Training classifier for NABIL\n",
      "AUC for NABIL: 0.499\n",
      "\n",
      "Training classifier for NIFRA\n",
      "AUC for NIFRA: 0.426\n",
      "\n",
      "Training classifier for UPPER\n",
      "AUC for UPPER: 0.421\n"
     ]
    }
   ],
   "source": [
    "for stock in STOCKS:\n",
    "    print(f\"\\nTraining classifier for {stock}\")\n",
    "\n",
    "    df = pd.read_csv(f\"{DATA_DIR}/{stock}.csv\")\n",
    "    prices = clean_close_series(df).flatten()\n",
    "\n",
    "    X = prices[:-1].reshape(-1, 1)\n",
    "    y = create_labels(prices)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, shuffle=False\n",
    "    )\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    joblib.dump(clf, f\"{MODEL_DIR}/{stock}_rf.pkl\")\n",
    "\n",
    "    # Predictions\n",
    "    probs = clf.predict_proba(X_test)[:, 1]\n",
    "    preds = clf.predict(X_test)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    with open(f\"{METRIC_DIR}/{stock}_confusion.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"matrix\": cm.tolist(),\n",
    "            \"labels\": [\"DOWN\", \"UP\"]\n",
    "        }, f)\n",
    "\n",
    "    # ROC\n",
    "    fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    with open(f\"{METRIC_DIR}/{stock}_roc.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"fpr\": fpr.tolist(),\n",
    "            \"tpr\": tpr.tolist(),\n",
    "            \"auc\": float(roc_auc)\n",
    "        }, f)\n",
    "\n",
    "    # Classification metrics\n",
    "    metrics_payload = {\n",
    "        \"accuracy\": float(accuracy_score(y_test, preds)),\n",
    "        \"precision\": float(precision_score(y_test, preds, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_test, preds, zero_division=0)),\n",
    "        \"f1\": float(f1_score(y_test, preds, zero_division=0))\n",
    "    }\n",
    "    with open(f\"{METRIC_DIR}/{stock}_classification_metrics.json\", \"w\") as f:\n",
    "        json.dump(metrics_payload, f)\n",
    "\n",
    "    report = classification_report(y_test, preds, target_names=[\"DOWN\", \"UP\"], output_dict=True, zero_division=0)\n",
    "    with open(f\"{METRIC_DIR}/{stock}_classification_report.json\", \"w\") as f:\n",
    "        json.dump(report, f)\n",
    "\n",
    "    print(f\"AUC for {stock}: {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4b1df80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CGH</td>\n",
       "      <td>4341.629708</td>\n",
       "      <td>65.891044</td>\n",
       "      <td>54.355796</td>\n",
       "      <td>0.143552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LICN</td>\n",
       "      <td>8053.173824</td>\n",
       "      <td>89.739478</td>\n",
       "      <td>45.737159</td>\n",
       "      <td>0.944712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NABIL</td>\n",
       "      <td>244.344591</td>\n",
       "      <td>15.631526</td>\n",
       "      <td>12.036249</td>\n",
       "      <td>0.886421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NIFRA</td>\n",
       "      <td>65.715811</td>\n",
       "      <td>8.106529</td>\n",
       "      <td>5.859517</td>\n",
       "      <td>0.502378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UPPER</td>\n",
       "      <td>20.323639</td>\n",
       "      <td>4.508175</td>\n",
       "      <td>3.164738</td>\n",
       "      <td>0.854404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stock          MSE       RMSE        MAE        R2\n",
       "0    CGH  4341.629708  65.891044  54.355796  0.143552\n",
       "1   LICN  8053.173824  89.739478  45.737159  0.944712\n",
       "2  NABIL   244.344591  15.631526  12.036249  0.886421\n",
       "3  NIFRA    65.715811   8.106529   5.859517  0.502378\n",
       "4  UPPER    20.323639   4.508175   3.164738  0.854404"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for stock in STOCKS:\n",
    "    data = pd.read_json(f\"{METRIC_DIR}/{stock}_regression_curve.json\")\n",
    "\n",
    "    mse = mean_squared_error(data[\"actual\"], data[\"predicted\"])\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(data[\"actual\"], data[\"predicted\"])\n",
    "    r2 = r2_score(data[\"actual\"], data[\"predicted\"])\n",
    "\n",
    "    rows.append({\n",
    "        \"Stock\": stock,\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2\": r2\n",
    "    })\n",
    "\n",
    "lstm_table = pd.DataFrame(rows)\n",
    "lstm_table\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
